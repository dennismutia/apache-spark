{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "from pathlib import Path\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import DataFrame, SparkSession\n",
    "from pyspark.sql.types import (\n",
    "    StructType,\n",
    "    StructField,\n",
    "    StringType,\n",
    "    IntegerType,\n",
    "    BooleanType,\n",
    "    FloatType,\n",
    ")\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=1)\n",
    "def get_spark():\n",
    "    sc = SparkContext(master=\"local[1]\", appName=\"ML Logs Transformer\")\n",
    "    spark = SparkSession(sc)\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_logs(logs_path: Path) -> DataFrame:\n",
    "    \"\"\"\n",
    "    TODO(Part 1.1): Complete this method\n",
    "    \"\"\"\n",
    "    # logs = []\n",
    "    # logs_path = \"app/logs.jsonl\"\n",
    "    logs = get_spark().read.json(logs_path)\n",
    "    return get_spark().createDataFrame(\n",
    "        logs,\n",
    "        StructType(\n",
    "            [\n",
    "                StructField(\"logId\", StringType()),\n",
    "                StructField(\"expId\", IntegerType()),\n",
    "                StructField(\"metricId\", IntegerType()),\n",
    "                StructField(\"valid\", BooleanType()),\n",
    "                StructField(\"createdAt\", StringType()),\n",
    "                StructField(\"ingestedAt\", StringType()),\n",
    "                StructField(\"step\", IntegerType()),\n",
    "                StructField(\"value\", FloatType()),\n",
    "            ]\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_experiments(experiments_path: Path) -> DataFrame:\n",
    "    \"\"\"\n",
    "    TODO(Part 1.2): Complete this method\n",
    "    \"\"\"\n",
    "    # experiments = []\n",
    "    # experiments_path = \"app/experiments.csv\"\n",
    "    experiments = get_spark().read.csv(experiments_path)\n",
    "    return get_spark().createDataFrame(\n",
    "        experiments,\n",
    "        StructType(\n",
    "            [StructField(\"expId\", IntegerType()), StructField(\"expName\", StringType())]\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_metrics(metrics_path: Path) -> DataFrame:\n",
    "    \"\"\"\n",
    "    TODO (Part 1.3): Complete this method\n",
    "    \"\"\"\n",
    "    # metrics = []\n",
    "    # metrics_path = \"app/metrics.csv\"\n",
    "    metrics = [\n",
    "        {\"metricId\": 0, \"metricName\": \"Loss\"},\n",
    "        {\"metricId\": 1, \"metricName\": \"Accuracy\"},\n",
    "    ]\n",
    "    return get_spark().createDataFrame(\n",
    "        metrics,\n",
    "        StructType(\n",
    "            [\n",
    "                StructField(\"metricId\", IntegerType()),\n",
    "                StructField(\"metricName\", StringType()),\n",
    "            ]\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_tables(\n",
    "    logs: DataFrame, experiments: DataFrame, metrics: DataFrame\n",
    ") -> DataFrame:\n",
    "    \"\"\"\n",
    "    TODO (Part 1.4): Complete this method\n",
    "    \"\"\"\n",
    "    # joined = []\n",
    "    joined_tables = logs.join(experiments, \"expId\", \"left\").join(metrics, \"metricId\", \"left\")\n",
    "    return get_spark().createDataFrame(\n",
    "        joined_tables,\n",
    "        StructType(\n",
    "            [\n",
    "                StructField(\"logId\", StringType()),\n",
    "                StructField(\"expId\", IntegerType()),\n",
    "                StructField(\"expName\", StringType()),\n",
    "                StructField(\"metricId\", IntegerType()),\n",
    "                StructField(\"metricName\", StringType()),\n",
    "                StructField(\"valid\", BooleanType()),\n",
    "                StructField(\"createdAt\", StringType()),\n",
    "                StructField(\"ingestedAt\", StringType()),\n",
    "                StructField(\"step\", IntegerType()),\n",
    "                StructField(\"value\", FloatType()),\n",
    "            ]\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_late_logs(data: DataFrame, hours: int) -> DataFrame:\n",
    "    \"\"\"\n",
    "    TODO(Part 3): Complete this method\n",
    "    \"\"\"\n",
    "    filtered_logs = data.filter(data.ingestedAt > hours)\n",
    "    return get_spark().createDataFrame(\n",
    "        filtered_logs,\n",
    "        StructType(\n",
    "            [\n",
    "                StructField(\"logId\", StringType()),\n",
    "                StructField(\"expId\", IntegerType()),\n",
    "                StructField(\"expName\", StringType()),\n",
    "                StructField(\"metricId\", IntegerType()),\n",
    "                StructField(\"metricName\", StringType()),\n",
    "                StructField(\"valid\", BooleanType()),\n",
    "                StructField(\"createdAt\", StringType()),\n",
    "                StructField(\"ingestedAt\", StringType()),\n",
    "                StructField(\"step\", IntegerType()),\n",
    "                StructField(\"value\", FloatType()),\n",
    "            ]\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_experiment_final_scores(data: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    TODO(Part 4): Complete this method\n",
    "    \"\"\"\n",
    "    scores = data.groupBy(\"expId\", \"metricId\", \"expName\", \"metricName\").agg({\"value\": \"max\"}).alias(\"maxValue\").agg({\"value\": \"min\"}).alias(\"minValue\")\n",
    "\n",
    "    return get_spark().createDataFrame(\n",
    "        scores,\n",
    "        StructType(\n",
    "            [\n",
    "                StructField(\"expId\", IntegerType()),\n",
    "                StructField(\"metricId\", IntegerType()),\n",
    "                StructField(\"expName\", StringType()),\n",
    "                StructField(\"metricName\", StringType()),\n",
    "                StructField(\"maxValue\", FloatType()),\n",
    "                StructField(\"minValue\", FloatType()),\n",
    "            ]\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(data: DataFrame, output_path: Path):\n",
    "    \"\"\"\n",
    "    TODO(Part 5): Complete this method\n",
    "    \"\"\"\n",
    "    data.write.csv(output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
